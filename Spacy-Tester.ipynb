{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda install -c conda-forge spacy\n",
    "\n",
    "conda install -c conda-forge spacy-lookups-data\n",
    "\n",
    "**python -m spacy download de_core_news_sm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Ihre Majestät die Königin Augusta verweilt noch in England zum Besuche bei der Königin Victoria. Die hohe Frau hat einige Sehenswürdigkeiten der Nachbarschaft in Augenschein genommen, auch ein paar Besuche in London bei Gliedern des englischen Königshauses gemacht. Im Uebrigen führen die königlichen Freundinnen auf Schloß Windsor das einfachste und stillste Familienleben. In wenigen Tagen verläßt die Königin den englischen Hof, um sich zunächst nach Koblenz zurückzubegeben.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "satz = 'Ihre Majestät die Königin Augusta verweilt noch in England zum Besuche bei der Königin Victoria. Die hohe Frau hat einige Sehenswürdigkeiten der Nachbarschaft in Augenschein genommen, auch ein paar Besuche in London bei Gliedern des englischen Königshauses gemacht. Im Uebrigen führen die königlichen Freundinnen auf Schloß Windsor das einfachste und stillste Familienleben. In wenigen Tagen verläßt die Königin den englischen Hof, um sich zunächst nach Koblenz zurückzubegeben.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    '''Lemmatize words.\n",
    "    Input: Text\n",
    "    Return: lemmatized text'''\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mein', 'Majestät', 'der', 'Königin', 'Augusta', 'verweilen', 'noch', 'in', 'England', 'zum', 'Besuch', 'bei', 'der', 'Königin', 'Victoria', '.', 'der', 'hoch', 'Frau', 'hateinige', 'Sehenswürdigkeiten', 'der', 'Nachbarschaft', 'in', 'Augenschein', 'nehmen', ',', 'auch', 'einen', 'paar', 'Besuch', 'in', 'London', 'bei', 'Glied', 'der', 'englisch', 'Königshauses', 'machen', '.', 'Im', 'Uebrigen', 'fahren', 'der', 'königlich', 'Freundin', 'auf', 'Schloß', 'Windsor', 'der', 'einfach', 'und', 'stillste', 'Familienleben', '.', 'In', 'wenig', 'Tag', 'verlassen', 'der', 'Königin', 'der', 'englisch', 'Hof', ',', 'um', 'sich', 'zunächst', 'nach', 'Koblenz', 'zurückbegeben', '.']\n"
     ]
    }
   ],
   "source": [
    "print([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ihre mein\n",
      "Majestät Majestät\n",
      "die der\n",
      "Königin Königin\n",
      "Augusta Augusta\n",
      "verweilt verweilen\n",
      "noch noch\n",
      "in in\n",
      "England England\n",
      "zum zum\n",
      "Besuche Besuch\n",
      "bei bei\n",
      "der der\n",
      "Königin Königin\n",
      "Victoria Victoria\n",
      ". .\n",
      "Die der\n",
      "hohe hoch\n",
      "Frau Frau\n",
      "hateinige hateinige\n",
      "Sehenswürdigkeiten Sehenswürdigkeiten\n",
      "der der\n",
      "Nachbarschaft Nachbarschaft\n",
      "in in\n",
      "Augenschein Augenschein\n",
      "genommen nehmen\n",
      ", ,\n",
      "auch auch\n",
      "ein einen\n",
      "paar paar\n",
      "Besuche Besuch\n",
      "in in\n",
      "London London\n",
      "bei bei\n",
      "Gliedern Glied\n",
      "des der\n",
      "englischen englisch\n",
      "Königshauses Königshauses\n",
      "gemacht machen\n",
      ". .\n",
      "Im Im\n",
      "Uebrigen Uebrigen\n",
      "führen fahren\n",
      "die der\n",
      "königlichen königlich\n",
      "Freundinnen Freundin\n",
      "auf auf\n",
      "Schloß Schloß\n",
      "Windsor Windsor\n",
      "das der\n",
      "einfachste einfach\n",
      "und und\n",
      "stillste stillste\n",
      "Familienleben Familienleben\n",
      ". .\n",
      "In In\n",
      "wenigen wenig\n",
      "Tagen Tag\n",
      "verläßt verlassen\n",
      "die der\n",
      "Königin Königin\n",
      "den der\n",
      "englischen englisch\n",
      "Hof Hof\n",
      ", ,\n",
      "um um\n",
      "sich sich\n",
      "zunächst zunächst\n",
      "nach nach\n",
      "Koblenz Koblenz\n",
      "zurückzubegeben zurückbegeben\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "satz_lemma = lemmatizer(satz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mein Majestät der Königin Augusta verweilen noch in England zum Besuch bei der Königin Victoria . der hoch Frau haben einig Sehenswürdigkeiten der Nachbarschaft in Augenschein nehmen , auch einen paar Besuch in London bei Glied der englisch Königshauses machen . Im Uebrigen fahren der königlich Freundin auf Schloß Windsor der einfach und stillste Familienleben . In wenig Tag verlassen der Königin der englisch Hof , um sich zunächst nach Koblenz zurückbegeben .'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satz_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>full_date</th>\n",
       "      <th>year</th>\n",
       "      <th>year_month</th>\n",
       "      <th>article_count</th>\n",
       "      <th>article_counts_per_issue</th>\n",
       "      <th>article_length_chars</th>\n",
       "      <th>article_length_words</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>headline</th>\n",
       "      <th>article_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1863-07-01_01.txt</td>\n",
       "      <td>1863-07-01</td>\n",
       "      <td>1863</td>\n",
       "      <td>1863-07</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>7101</td>\n",
       "      <td>955</td>\n",
       "      <td>PC</td>\n",
       "      <td>Ist das Abgeordnetenhaus eine Obrigkeit?</td>\n",
       "      <td>Ist das Abgeordnetenhaus eine Obrigkeit?\\nEin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1863-07-01_02.txt</td>\n",
       "      <td>1863-07-01</td>\n",
       "      <td>1863</td>\n",
       "      <td>1863-07</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1083</td>\n",
       "      <td>129</td>\n",
       "      <td>PC</td>\n",
       "      <td>Wochenschau.</td>\n",
       "      <td>Wochenschau.\\nDie Nachrichten aus Karlsbad übe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1863-07-01_03.txt</td>\n",
       "      <td>1863-07-01</td>\n",
       "      <td>1863</td>\n",
       "      <td>1863-07</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>546</td>\n",
       "      <td>66</td>\n",
       "      <td>PC</td>\n",
       "      <td>Wochenschau.</td>\n",
       "      <td>Ihre Majestät die Königin Augusta verweilt noc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1863-07-01_04.txt</td>\n",
       "      <td>1863-07-01</td>\n",
       "      <td>1863</td>\n",
       "      <td>1863-07</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2145</td>\n",
       "      <td>310</td>\n",
       "      <td>PC</td>\n",
       "      <td>Wochenschau.</td>\n",
       "      <td>Se. Königl. Hoheit der Kronprinz hat von Litth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1863-07-01_05.txt</td>\n",
       "      <td>1863-07-01</td>\n",
       "      <td>1863</td>\n",
       "      <td>1863-07</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1904</td>\n",
       "      <td>260</td>\n",
       "      <td>PC</td>\n",
       "      <td>Wochenschau.</td>\n",
       "      <td>Es muß der Regierung zu großer Befriedigung ge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename   full_date  year year_month  article_count  \\\n",
       "0  1863-07-01_01.txt  1863-07-01  1863    1863-07              1   \n",
       "1  1863-07-01_02.txt  1863-07-01  1863    1863-07              2   \n",
       "2  1863-07-01_03.txt  1863-07-01  1863    1863-07              3   \n",
       "3  1863-07-01_04.txt  1863-07-01  1863    1863-07              4   \n",
       "4  1863-07-01_05.txt  1863-07-01  1863    1863-07              5   \n",
       "\n",
       "   article_counts_per_issue  article_length_chars  article_length_words  \\\n",
       "0                         9                  7101                   955   \n",
       "1                         9                  1083                   129   \n",
       "2                         9                   546                    66   \n",
       "3                         9                  2145                   310   \n",
       "4                         9                  1904                   260   \n",
       "\n",
       "  newspaper                                  headline  \\\n",
       "0        PC  Ist das Abgeordnetenhaus eine Obrigkeit?   \n",
       "1        PC                              Wochenschau.   \n",
       "2        PC                              Wochenschau.   \n",
       "3        PC                              Wochenschau.   \n",
       "4        PC                              Wochenschau.   \n",
       "\n",
       "                                        article_text  \n",
       "0  Ist das Abgeordnetenhaus eine Obrigkeit?\\nEin ...  \n",
       "1  Wochenschau.\\nDie Nachrichten aus Karlsbad übe...  \n",
       "2  Ihre Majestät die Königin Augusta verweilt noc...  \n",
       "3  Se. Königl. Hoheit der Kronprinz hat von Litth...  \n",
       "4  Es muß der Regierung zu großer Befriedigung ge...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read data \n",
    "path_to_csv_file = ### path to csv file\n",
    "\n",
    "df = pd.read_csv(path_to_csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[:15, :]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "def lemmatizer(text, nlp):\n",
    "    '''Lemmatize words.\n",
    "    Input: Text\n",
    "    Return: lemmatized text'''\n",
    "        \n",
    "    doc = nlp(str(text))\n",
    "    return ' '.join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.51 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    sein der Abgeordnetenhaus einen Obrigkeit ? \\n...\n",
       "1    Wochenschau . \\n der Nachricht aus Karlsbad üb...\n",
       "2    mein Majestät der Königin Augusta verweilen no...\n",
       "3    Se . Königl . Hoheit der Kronprinz haben von L...\n",
       "4    ich muß der Regierung zu groß Befriedigung ger...\n",
       "5    Ein Schriftstück , welch zuerst in einer Blatt...\n",
       "6    Was der Stand der Ding in Pol betreffen , so l...\n",
       "7    außer der sonstig Mittel einer verzweifeln Sch...\n",
       "8    der Vorstellung von Frankreich , England und O...\n",
       "9    sein der Abgeordnetenhaus einen Obrigkeit ? Na...\n",
       "Name: article_text_processed, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Lemmatization\n",
    "df.loc[:,'article_text_processed'] = df.loc[:,'article_text'].apply(lambda x: lemmatizer(x, nlp))\n",
    "\n",
    "# Print out the first rows of papers\n",
    "df.loc[:,'article_text_processed'].head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer(2.5, nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER - Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = [ent for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Augusta,\n",
       " England,\n",
       " Victoria,\n",
       " Augenschein,\n",
       " London,\n",
       " englischen,\n",
       " Windsor,\n",
       " englischen,\n",
       " Koblenz]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aus: https://data-science-blog.com/blog/2018/10/18/einstieg-in-natural-language-processing-teil-2-preprocessing-von-rohtext-mit-python/, Zugriff: 30.6.2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')\n",
    "\n",
    "def ner (text, nlp):\n",
    "    '''Lemmatize words.\n",
    "    Input: Text\n",
    "    Return: Named entities'''\n",
    "        \n",
    "    doc = nlp(str(text))\n",
    "    return [ent for ent in doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(Abgeordnetenhaus), (GeistlicherPastor, Feldn...\n",
       "1    [(Wochenschau), (Karlsbad), (Derselbe), (Karls...\n",
       "2    [(Augusta), (England), (Victoria), (Augenschei...\n",
       "3    [(Königl), (Litthauen), (Kronprinzessin), (Rei...\n",
       "4    [(Erwarten), (Tag, für, Tag, Besorgniß), (Kurz...\n",
       "5    [(Elbing), (Berlin), (Rath), (Preußens), (Fran...\n",
       "6    [(Polen), (preußisch-polnischen, Grenze), (nah...\n",
       "7       [(Comitéin, Warschau), (Revolutions-Tribunal)]\n",
       "8    [(Frankreich), (England), (Oesterreich), (poln...\n",
       "9    [(Abgeordnetenhaus), (Elberfeld), (preußischen...\n",
       "Name: named_entities, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'named_entities'] = df.loc[:,'article_text'].apply(lambda x: ner(x, nlp))\n",
    "\n",
    "# Print out the first rows of papers\n",
    "df.loc[:,'named_entities'].head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Textabschnitte\n",
    "doc.text                                 # Originaltext\n",
    "sents = doc.sents                        # Sätze des Dokuments\n",
    "tokens = [token for token in doc]        # Tokens/Worte des Dokuments\n",
    "parags = doc.text_with_ws.split('\\n\\n')  # Absätze des Dokuments\n",
    " \n",
    "# Eigenschaften einzelner Tokens\n",
    "[t.lemma_ for t in doc]                  # Lemmata der einzelnen Tokens\n",
    "[t.tag_ for t in doc]                    # POS-Tags der einzelnen Tokens\n",
    " \n",
    "# Objekte zur Textanalyse\n",
    "doc.vocab                                # Vokabular des Dokuments\n",
    "doc.sentiment                            # Sentiment des Dokuments\n",
    "doc.noun_chunks                          # NounChunks des Dokuments\n",
    "entities = [ent for ent in doc.ents]     # Named Entities (Persons, Locations, Countrys)\n",
    " \n",
    "# Objekte zur Dokumentenklassifikation\n",
    "doc.vector                               # Vektor\n",
    "doc.tensor                               # Tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
